{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"\n# <span style=\"color:teal\"> RSNA Screening Mammography Breast Cancer Detection<a class=\"anchor\"  id=\"projectTopic\"></a></span>\n### <span style=\"color:teal\"> Detect breast cancers in screening mammograms <a class=\"anchor\"  id=\"detect\"></a></span>","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:teal\">Developed by : <a class=\"anchor\"  id=\"detect\"></a></span>\n\n* [Gebreyowhans Hailekiros](https://www.kaggle.com/gebreyowhansbahre/)\n<!-- * [Mahbub Hasan](https://www.kaggle.com/mahbubulhasan/) -->\n* [Muhammad Danish Sadiq](https://www.kaggle.com/muhammaddanishsadiq/)","metadata":{}},{"cell_type":"markdown","source":"* This notebook is developed to make inference on the trained model [RSNA_BCD_Train[TPU_VM]_EfficientNet](https://www.kaggle.com/code/gebreyowhansbahre/rsna-bcd-train-tpu-vm-bc86d1) using unseen test data and submit it to competition. Since we trained to models during training; we have to use average of the predictions of the two models to get the final prediction.","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:teal\"> Notebooks <a class=\"anchor\"  id=\"notebooks\"></a></span>\n* Image preprocessing Notebook: [RSNA_BCD_DICOM_PNG_ROI](https://www.kaggle.com/code/gebreyowhansh/rsna-bcd-dicom-png-roi)\n\n* Training Notebook: [RSNA_BCD_Train[TPU_VM]_EfficientNet](https://www.kaggle.com/code/gebreyowhansbahre/rsna-bcd-train-tpu-vm-bc86d1)\n\n* Test Notebook: [RSNA-BCD-GPU-TEST_EfficientNet](https://www.kaggle.com/code/gebreyowhansbahre/rsna-bcd-gpu-test/edit/run/128324368)\n\n ","metadata":{}},{"cell_type":"markdown","source":"# <span style=\"color:teal\">1. Imporing and installing libraries <a class=\"anchor\"  id=\"libraries\"></a></span>","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install -qU --upgrade pip\nclear_output()\n!pip install -qU /kaggle/input/whl-files/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl/dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n!pip install -qU /kaggle/input/whl-files/pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl/pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -qU /kaggle/input/whl-files/python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl/python_gdcm-3.0.20-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:16:33.371970Z","iopub.execute_input":"2023-05-05T16:16:33.372983Z","iopub.status.idle":"2023-05-05T16:20:39.357598Z","shell.execute_reply.started":"2023-05-05T16:16:33.372936Z","shell.execute_reply":"2023-05-05T16:20:39.356304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, random, cv2, dicomsdl\nimport numpy as np\nimport pandas as pd\nfrom IPython import display as ipd\n\nfrom tqdm import tqdm\nfrom joblib import Parallel, delayed\nfrom matplotlib import pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.python.client import device_lib\nfrom kaggle_datasets import KaggleDatasets\nfrom kaggle_secrets import UserSecretsClient\n\n\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\ntf.get_logger().setLevel('ERROR')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.361293Z","iopub.execute_input":"2023-05-05T16:20:39.361652Z","iopub.status.idle":"2023-05-05T16:20:39.370442Z","shell.execute_reply.started":"2023-05-05T16:20:39.361616Z","shell.execute_reply":"2023-05-05T16:20:39.369274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('np:', np.__version__)\nprint('pd:', pd.__version__)\nprint('tf:',tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.371709Z","iopub.execute_input":"2023-05-05T16:20:39.372323Z","iopub.status.idle":"2023-05-05T16:20:39.381550Z","shell.execute_reply.started":"2023-05-05T16:20:39.372283Z","shell.execute_reply":"2023-05-05T16:20:39.380324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\"> 2. Create basic configuration class <a class=\"anchor\"  id=\"configuration\"></a></span>\n * Configuration class consisting of information about project","metadata":{}},{"cell_type":"code","source":"class Config:\n    \n    def __init__(self):\n        \n        self.debug = False\n        \n        self.device = 'GPU'\n        self.num_devices = 1\n#         self.model_name = 'EfficientNetB3'\n        self.seed = 150\n        \n        self.models_path = '/kaggle/input/rsna-bcd-train-tpu-vm-bc86d1/'\n        \n        self.weights = \"/kaggle/input/whl-files/efficientnetb3_notop.h5/efficientnetb3_notop.h5\"\n        \n        self.input_data_path = '/kaggle/input/rsna-breast-cancer-detection/'\n        \n        self.output_path = '/kaggle/working/'\n        self.test_images_path=self.output_path+'test_images/'\n        \n        self.test_path = self.input_data_path + 'test_images/'\n        self.test_csv = self.input_data_path + 'test.csv'\n        \n        self.sub_csv = '/kaggle/working/submission.csv'  \n        self.sample_sub_csv = self.input_data_path + 'sample_submission.csv'\n        self.models = ['model_3.h5','model_4.h5']\n        \n        self.threshold = 0.6\n        \n        self.batch_size=32\n        self.epochs=10\n        self.dropout=0.4\n        self.optimizer='adam'\n        self.loss='binary_crossentropy'\n        \n        self.img_size =(512,256)\n        self.resize_dim = 512\n        self.img_ext = 'png'\n\nconfig = Config()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.384879Z","iopub.execute_input":"2023-05-05T16:20:39.385668Z","iopub.status.idle":"2023-05-05T16:20:39.395272Z","shell.execute_reply.started":"2023-05-05T16:20:39.385627Z","shell.execute_reply":"2023-05-05T16:20:39.394268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\"> 3. Device Configurations <a class=\"anchor\"  id=\"configuration\"></a></span>","metadata":{}},{"cell_type":"code","source":"num_devices = len(tf.config.list_physical_devices('GPU'))\n\nif num_devices > 1:\n    config.num_devices = num_devices\n    strategy = tf.distribute.MirroredStrategy()\n    print(f'Running on {num_devices} GPU devices')\nelif num_devices == 1:\n    strategy = tf.distribute.get_strategy()\n    print(f'Running on {num_devices} GPU device')\nelse:\n    strategy = tf.distribute.get_strategy()\n    config.device = 'CPU'\n    print(f'Running on CPU')\n\ntf.config.optimizer.set_jit(True)\ntf.keras.mixed_precision.set_global_policy(policy=\"float32\")\nconfig.batch_size = config.batch_size * config.num_devices","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.397085Z","iopub.execute_input":"2023-05-05T16:20:39.397471Z","iopub.status.idle":"2023-05-05T16:20:39.410119Z","shell.execute_reply.started":"2023-05-05T16:20:39.397436Z","shell.execute_reply":"2023-05-05T16:20:39.408993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">4.Functions to convert ,extract ROI and save dicom images <a class=\"anchor\"  id=\"utilityfunctions\"></a></span>\n ","metadata":{}},{"cell_type":"markdown","source":"### <span style=\"color:teal\">4.1 Dicom to png <a class=\"anchor\"  id=\"dicomtopng\"></a></span>","metadata":{}},{"cell_type":"code","source":"def dicom_to_png(dicom_path):\n    dicom = dicomsdl.open(dicom_path)\n    image = dicom.pixelData(storedvalue=False)\n    image = image - np.min(image)\n    image = image / np.max(image)\n\n    if dicom.PhotometricInterpretation == 'MONOCHROME1':\n        image = 1.0 - image\n        \n    image = cv2.resize(image, (config.resize_dim, config.resize_dim), interpolation=cv2.INTER_LINEAR)\n    image = (image * 255).astype(np.uint8)\n    return image\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.411514Z","iopub.execute_input":"2023-05-05T16:20:39.412639Z","iopub.status.idle":"2023-05-05T16:20:39.419949Z","shell.execute_reply.started":"2023-05-05T16:20:39.412601Z","shell.execute_reply":"2023-05-05T16:20:39.418943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:teal\">4.2 Extract region of interest <a class=\"anchor\"  id=\"regionofInterest\"></a></span>","metadata":{}},{"cell_type":"code","source":"def png_to_roi(image, image_path):\n    bin_image = cv2.threshold(image, 20, 255, cv2.THRESH_BINARY)[1]\n    contours, _ = cv2.findContours(bin_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n    contour = max(contours, key=cv2.contourArea)\n    ys = contour.squeeze()[:, 0]\n    xs = contour.squeeze()[:, 1]\n    roi = image[np.min(xs):np.max(xs), np.min(ys):np.max(ys)]\n    return cv2.resize(roi, config.img_size[::-1], interpolation=cv2.INTER_LINEAR)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.421509Z","iopub.execute_input":"2023-05-05T16:20:39.421940Z","iopub.status.idle":"2023-05-05T16:20:39.431189Z","shell.execute_reply.started":"2023-05-05T16:20:39.421898Z","shell.execute_reply":"2023-05-05T16:20:39.430273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(dicom_path, image_path):\n    image = dicom_to_png(dicom_path)\n    os.makedirs(os.path.dirname(image_path), exist_ok=True)\n    image = png_to_roi(image, image_path)\n    cv2.imwrite(image_path, image)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.432650Z","iopub.execute_input":"2023-05-05T16:20:39.433187Z","iopub.status.idle":"2023-05-05T16:20:39.441255Z","shell.execute_reply.started":"2023-05-05T16:20:39.433149Z","shell.execute_reply":"2023-05-05T16:20:39.440282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\"> 5. Dataframe informations <a class=\"anchor\"  id=\"dataframeinfo\"></a></span>","metadata":{}},{"cell_type":"code","source":"print('\\n  Train:')\ntrain_df = pd.read_csv(config.input_data_path + 'train.csv')\ndisplay(train_df.head())\n\nprint('\\n  Test :')\ntest_df = pd.read_csv(config.test_csv)\ntest_df['dicom_path'] = config.test_path + test_df['patient_id'].astype(str) + '/' + test_df['image_id'].astype(str) + '.dcm'\ntest_df['image_path'] = config.test_images_path + test_df['patient_id'].astype(str) + '/' + test_df['image_id'].astype(str) + '.png'\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.444467Z","iopub.execute_input":"2023-05-05T16:20:39.444734Z","iopub.status.idle":"2023-05-05T16:20:39.546467Z","shell.execute_reply.started":"2023-05-05T16:20:39.444710Z","shell.execute_reply":"2023-05-05T16:20:39.545190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.551189Z","iopub.execute_input":"2023-05-05T16:20:39.552486Z","iopub.status.idle":"2023-05-05T16:20:39.565516Z","shell.execute_reply.started":"2023-05-05T16:20:39.552437Z","shell.execute_reply":"2023-05-05T16:20:39.564281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Parallel(n_jobs=4, backend='threading')(delayed(process)(dicom_path, image_path) \n                   for dicom_path, image_path in tqdm(zip(test_df['dicom_path'], \n                                                          test_df['image_path'])))\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:39.567516Z","iopub.execute_input":"2023-05-05T16:20:39.568371Z","iopub.status.idle":"2023-05-05T16:20:42.288438Z","shell.execute_reply.started":"2023-05-05T16:20:39.568328Z","shell.execute_reply":"2023-05-05T16:20:42.287448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### <span style=\"color:teal\"> Check If Data Exists ? <a class=\"anchor\"  id=\"existence\"></a></span>","metadata":{}},{"cell_type":"code","source":"tf.io.gfile.exists(test_df.dicom_path.iloc[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.290137Z","iopub.execute_input":"2023-05-05T16:20:42.290727Z","iopub.status.idle":"2023-05-05T16:20:42.299400Z","shell.execute_reply.started":"2023-05-05T16:20:42.290688Z","shell.execute_reply":"2023-05-05T16:20:42.298270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">6. Defining input features <a class=\"anchor\"  id=\"inputefeatures\"></a></span>","metadata":{}},{"cell_type":"code","source":"train_df_processed = pd.read_csv('/kaggle/input/rsna-bcd-processed-file/train_df_Processed.csv')\n    \nprocessed_train_df_columns = train_df_processed.columns\nprocessed_train_df_columns = np.append(processed_train_df_columns, 'prediction_id')\nprint(processed_train_df_columns)\n\ntest_df = pd.DataFrame(test_df, columns=processed_train_df_columns).fillna(0.0)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.301276Z","iopub.execute_input":"2023-05-05T16:20:42.301639Z","iopub.status.idle":"2023-05-05T16:20:42.470718Z","shell.execute_reply.started":"2023-05-05T16:20:42.301605Z","shell.execute_reply":"2023-05-05T16:20:42.469604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.472410Z","iopub.execute_input":"2023-05-05T16:20:42.473109Z","iopub.status.idle":"2023-05-05T16:20:42.487047Z","shell.execute_reply.started":"2023-05-05T16:20:42.473067Z","shell.execute_reply":"2023-05-05T16:20:42.485964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"exclude_cols = ['patient_id', 'image_id', 'site_id','machine_id', 'cancer', 'age', 'stratify', \n                'image_path', 'fold', 'prediction_id']\ninput_features = test_df.columns.difference(exclude_cols)\n\ninput_features","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.488746Z","iopub.execute_input":"2023-05-05T16:20:42.489129Z","iopub.status.idle":"2023-05-05T16:20:42.496935Z","shell.execute_reply.started":"2023-05-05T16:20:42.489094Z","shell.execute_reply":"2023-05-05T16:20:42.495927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">7. Normalize the inpute features <a class=\"anchor\"  id=\"nomalization\"></a></span>","metadata":{}},{"cell_type":"code","source":"test_df[input_features] = (test_df[input_features] - train_df_processed[input_features].mean()) / train_df_processed[input_features].std()\ntest_df[input_features] = test_df[input_features].astype('float32')\n\ntest_df[input_features]","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.498433Z","iopub.execute_input":"2023-05-05T16:20:42.499053Z","iopub.status.idle":"2023-05-05T16:20:42.542145Z","shell.execute_reply.started":"2023-05-05T16:20:42.499011Z","shell.execute_reply":"2023-05-05T16:20:42.541089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">8. Data Pipeline <a class=\"anchor\"  id=\"pipline\"></a></span>\n\n### <span style=\"color:teal\">8.1 Decode images <a class=\"anchor\"  id=\"decode\"></a></span>\n * **tf.image.decode_png()** and **tf.image.decode_jpeg** are TensorFlow functions that decodes a PNG-encoded   image into a tensor of type uint8.\n \n * These functions takes the following arguments: \n     * **image**: A string tensor containing a PNG or jpeg -encoded image.\n     * **channels**: An optional integer specifying the number of color channels in the decoded image. By  default, this is set to 3,\n     \n\n* The function returns a **uint8** tensor representing the decoded image with the shape of (height, width, channels) \n ","metadata":{}},{"cell_type":"code","source":"def decode_image(label=True, img_size=config.img_size, ext=config.img_ext):\n    \n    def _decode_image(Input_Image, label=None):\n        image = tf.io.read_file(Input_Image['input_image'])\n        \n        if ext == 'png':\n            ## PNG-encoded image into a tensor of type uint8.\n            image = tf.image.decode_png(image, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            ## jpeg-encoded image into a tensor of type uint8.\n            image = tf.image.decode_jpeg(image, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n        \n        ## explicit size needed for TPU\n        image = tf.image.resize(image, img_size)\n        ## convert image to floats in [0, 1] range\n        image = tf.cast(image, tf.float32) / 255.0\n        \n        Input_Image['input_image'] = image\n        \n        if label is None:\n            return Input_Image\n        else:\n            return Input_Image, label\n    \n    if label:\n        return _decode_image\n    else:\n        return lambda x: _decode_image(x, None)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.543873Z","iopub.execute_input":"2023-05-05T16:20:42.544276Z","iopub.status.idle":"2023-05-05T16:20:42.552406Z","shell.execute_reply.started":"2023-05-05T16:20:42.544216Z","shell.execute_reply":"2023-05-05T16:20:42.551273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:teal\">8.2 Data augumentation <a class=\"anchor\"  id=\"augumentation\"></a></span>\n* Using Augmentations to reduce overfitting and make model more robust by :\n * 1. random_flip_left_right for applying position transforamtion\n * 2. perofrming some random_hue,random_saturation,random_contrast,random_brightness for pixel transforamtion","metadata":{}},{"cell_type":"code","source":"def data_augment(label=True):\n    def _augment(Input_Image, label=None):\n        image = Input_Image['input_image']\n        #position transforamtion\n        image = tf.image.random_flip_left_right(image)\n        # pixel-augment\n        image = tf.image.random_hue(image, config.hue)\n        image = tf.image.random_saturation(image,config.sat[0], config.sat[1])\n        image = tf.image.random_contrast(image,config.cont[0], config.cont[1])\n        image = tf.image.random_brightness(image,config.bri)\n        Input_Image['input_image'] = image\n        if label is not None:\n            return Input_Image, label\n        else:\n            return Input_Image\n\n    if label:\n        return _augment\n    else:\n        return lambda x: _augment(x, None)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.555029Z","iopub.execute_input":"2023-05-05T16:20:42.556371Z","iopub.status.idle":"2023-05-05T16:20:42.565204Z","shell.execute_reply.started":"2023-05-05T16:20:42.556330Z","shell.execute_reply":"2023-05-05T16:20:42.564415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <span style=\"color:teal\">8.3 Build tf.data.dataset <a class=\"anchor\"  id=\"dataset\"></a></span>","metadata":{}},{"cell_type":"code","source":"def build_dataset(df,input_features,image_size=config.img_size,batch_size=config.batch_size, \n                  label=True,cache=False,ext=config.img_ext):\n    \n    decode = decode_image(label, img_size=image_size, ext=ext)\n    input_data = {'input_image': df['image_path'].values, 'input_features': df[input_features].values}\n    \n    if label:\n        label_data = df['cancer'].apply(lambda x: int(x)).values\n        dataset = tf.data.Dataset.from_tensor_slices((input_data, label_data))\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices(input_data)\n        \n    dataset = dataset.map(decode, num_parallel_calls=tf.data.AUTOTUNE)\n    \n    if cache:\n        dataset = dataset.cache()\n        \n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.566619Z","iopub.execute_input":"2023-05-05T16:20:42.567563Z","iopub.status.idle":"2023-05-05T16:20:42.578368Z","shell.execute_reply.started":"2023-05-05T16:20:42.567504Z","shell.execute_reply":"2023-05-05T16:20:42.577563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = build_dataset(test_df, input_features, \n                             batch_size=config.batch_size, \n                             label=False, \n                             cache=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.580712Z","iopub.execute_input":"2023-05-05T16:20:42.581423Z","iopub.status.idle":"2023-05-05T16:20:42.612767Z","shell.execute_reply.started":"2023-05-05T16:20:42.581386Z","shell.execute_reply":"2023-05-05T16:20:42.611861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for item in test_dataset.take(1):\n#     print(item)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.614197Z","iopub.execute_input":"2023-05-05T16:20:42.614663Z","iopub.status.idle":"2023-05-05T16:20:42.620025Z","shell.execute_reply.started":"2023-05-05T16:20:42.614623Z","shell.execute_reply":"2023-05-05T16:20:42.618898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">9. Evaluation metric(f1 score)<a class=\"anchor\"  id=\"dataset\"></a></span>","metadata":{}},{"cell_type":"code","source":"def p_f1(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.cast(y_pred, tf.float32)\n    \n    tp = tf.reduce_sum(y_true * y_pred)\n    tn = tf.reduce_sum((1 - y_true) * (1 - y_pred))\n    fp = tf.reduce_sum((1 - y_true) * y_pred)\n    fn = tf.reduce_sum(y_true * (1 - y_pred))\n    \n    p = tp / (tp + fp + tf.keras.backend.epsilon())\n    r = tp / (tp + fn + tf.keras.backend.epsilon())\n    \n    f1 = 2 * p * r / (p + r + tf.keras.backend.epsilon())\n    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n\n    return tf.reduce_mean(f1)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.621653Z","iopub.execute_input":"2023-05-05T16:20:42.623501Z","iopub.status.idle":"2023-05-05T16:20:42.632126Z","shell.execute_reply.started":"2023-05-05T16:20:42.623473Z","shell.execute_reply":"2023-05-05T16:20:42.631343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">10. Defining the model <a class=\"anchor\"  id=\"model\"></a></span>","metadata":{}},{"cell_type":"code","source":"def build_model(input_features, \n                loss=config.loss, \n                dropout=config.dropout, \n                optimizer=config.optimizer, \n                img_size=config.img_size):\n    with strategy.scope():\n        input_image = tf.keras.layers.Input(shape=(*img_size,3), name='input_image')\n        input_features = tf.keras.layers.Input(shape=[len(input_features)], name='input_features')\n        \n        efficientNetBase_model = tf.keras.applications.EfficientNetB3(input_shape=(*img_size,3),\n                                                 include_top=False, \n                                                 drop_connect_rate=0.3,\n                                                 weights=config.weights)(input_image)\n        \n        x = tf.keras.layers.GlobalAveragePooling2D()(efficientNetBase_model)\n        x = tf.keras.layers.Dense(512,activation=\"relu\")(x)\n        _output = tf.keras.layers.Dropout(dropout)(x)\n        _output = tf.keras.layers.BatchNormalization()(_output)\n        _output = tf.keras.layers.Dense(256,activation=\"relu\", kernel_regularizer=\n                                        tf.keras.regularizers.l2(0.01))(_output)\n        _output = tf.keras.layers.Dropout(dropout)(x)\n        _output = tf.keras.layers.BatchNormalization()(_output)\n        _output = tf.keras.layers.Concatenate()([_output, input_features])\n        _output = tf.keras.layers.Dense(1, activation='sigmoid')(_output)\n        \n        model = tf.keras.Model(inputs=[input_image, input_features], outputs=_output)\n        \n        model.compile(optimizer=optimizer,\n                      loss=loss,\n                      metrics=['accuracy', \n                               p_f1])\n\n        return model\n    \nmodel = build_model(input_features)\n# model.run_eagerly = True\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:42.633292Z","iopub.execute_input":"2023-05-05T16:20:42.634112Z","iopub.status.idle":"2023-05-05T16:20:47.835159Z","shell.execute_reply.started":"2023-05-05T16:20:42.634071Z","shell.execute_reply":"2023-05-05T16:20:47.834106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:47.836768Z","iopub.execute_input":"2023-05-05T16:20:47.837882Z","iopub.status.idle":"2023-05-05T16:20:48.035556Z","shell.execute_reply.started":"2023-05-05T16:20:47.837841Z","shell.execute_reply":"2023-05-05T16:20:48.034320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">11. Predictions <a class=\"anchor\"  id=\"prediction\"></a></span>","metadata":{}},{"cell_type":"code","source":"test_dataset = build_dataset(test_df, input_features, batch_size=config.batch_size,\n                             label=False, cache=False)\n\npredictions = []\n\nfor _mdl in config.models:\n    print(f'Predicting with model {_mdl}...')\n    model.load_weights(f'{config.models_path}/models/'+_mdl)\n    pred = model.predict(test_dataset)\n    predictions.append(pred)\n    \npredictions = np.mean(predictions, axis=0)\npredictions","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:48.037625Z","iopub.execute_input":"2023-05-05T16:20:48.038458Z","iopub.status.idle":"2023-05-05T16:20:55.756552Z","shell.execute_reply.started":"2023-05-05T16:20:48.038408Z","shell.execute_reply":"2023-05-05T16:20:55.755561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"color:teal\">12. Prepare submission data <a class=\"anchor\"  id=\"submission\"></a></span>","metadata":{}},{"cell_type":"code","source":"prediction_reshaped=predictions.reshape(-1)\nprint(\"Predictions after reshaped :\",prediction_reshaped)\n\nprediction_ids=test_df['prediction_id']\nprint(\"Prediction Id's : \",prediction_ids)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:55.758000Z","iopub.execute_input":"2023-05-05T16:20:55.758479Z","iopub.status.idle":"2023-05-05T16:20:55.767244Z","shell.execute_reply.started":"2023-05-05T16:20:55.758430Z","shell.execute_reply":"2023-05-05T16:20:55.765880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_df = pd.DataFrame({'prediction_id':prediction_ids, \n                        'cancer':prediction_reshaped})\npredicted_df","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:55.768901Z","iopub.execute_input":"2023-05-05T16:20:55.770727Z","iopub.status.idle":"2023-05-05T16:20:55.784262Z","shell.execute_reply.started":"2023-05-05T16:20:55.770690Z","shell.execute_reply":"2023-05-05T16:20:55.783293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv(config.sample_sub_csv)\ndel submission_df['cancer']\n\nsubmission_df = submission_df.merge(predicted_df, on='prediction_id', how='left')\nsubmission_df = submission_df.groupby('prediction_id')['cancer'].max().reset_index()\n\nsubmission_df.to_csv(config.sub_csv, index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:55.789424Z","iopub.execute_input":"2023-05-05T16:20:55.789692Z","iopub.status.idle":"2023-05-05T16:20:55.805352Z","shell.execute_reply.started":"2023-05-05T16:20:55.789667Z","shell.execute_reply":"2023-05-05T16:20:55.804129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:55.806667Z","iopub.execute_input":"2023-05-05T16:20:55.807184Z","iopub.status.idle":"2023-05-05T16:20:55.821261Z","shell.execute_reply.started":"2023-05-05T16:20:55.807147Z","shell.execute_reply":"2023-05-05T16:20:55.820109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-05T16:20:55.822789Z","iopub.execute_input":"2023-05-05T16:20:55.823174Z","iopub.status.idle":"2023-05-05T16:20:55.836031Z","shell.execute_reply.started":"2023-05-05T16:20:55.823139Z","shell.execute_reply":"2023-05-05T16:20:55.835023Z"},"trusted":true},"execution_count":null,"outputs":[]}]}